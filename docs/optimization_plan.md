# 优化方案：提升 AI 智商与记忆力

## 🎯 目标
解决 "模型太笨" 和 "记不住名字" 的问题。

## 🔍 问题分析
1. **智商问题**：目前使用的 `qwen2:1.5b` 参数量较小，逻辑推理和上下文理解能力有限。
2. **记忆问题**：当前代码仅将历史对话作为上下文传给模型。对于小模型，从长对话中"提取"关键信息（如名字）并保持一致性很难。

## 🛠️ 拟定方案

### 1. 升级模型（核心）
- **从 `qwen2:1.5b` 升级到 `qwen2.5:3b`**
- **理由**：Qwen2.5 是最新一代，3B 版本在推理能力上大幅提升，且 8GB 树莓派完全能跑（占用约 2.2GB 显存）。

### 2. 代码优化：显式记忆（Programmatic Memory）
- **现状**： relying on LLM to remember "My name is X" from history.
- **改进**：
  - 增加 **"信息提取"** 功能：当检测到用户介绍自己时，自动提取名字。
  - 增加 **"用户画像"** 存储：保存用户的名字、爱好等信息到 `config/user_profile.json`。
  - **强提示**：将 "你的主人是 [名字]" 直接写入系统提示词（System Prompt），强迫模型记住。

## 📝 实施步骤

### 步骤 1：更换模型
```bash
ollama pull qwen2.5:3b
```

### 步骤 2：修改 `src/brain/brain.py`
- 修改默认模型为 `qwen2.5:3b`
- 增加 `UserProfile` 类，用于管理用户信息
- 在 `chat` 流程中加入：
  - 检查是否包含用户名字信息
  - 动态更新系统提示词

### 步骤 3：验证
- 运行后直接问 "我是谁"
- 验证是否能秒回正确名字
- 验证对话逻辑是否更通顺

## ⚠️ 风险
- **响应速度**：3B 模型比 1.5B 慢一倍（预计 5-10 秒回复）。如果太慢，可以尝试 `llama3.2:3b`（速度可能稍快）。
