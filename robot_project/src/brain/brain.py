# AIæˆé•¿æœºå™¨äºº - AIå¤§è„‘æ¨¡å—
# åŒ…å«å¯¹è¯ã€è®°å¿†ã€äººæ ¼åŠŸèƒ½

import chromadb
from datetime import datetime
import json
import os
import time
import re

# API å®¢æˆ·ç«¯ï¼ˆå»¶è¿Ÿå¯¼å…¥ï¼‰
ollama = None
openai = None


def get_ollama():
    """å»¶è¿ŸåŠ è½½ ollama"""
    global ollama
    if ollama is None:
        import ollama as _ollama
        ollama = _ollama
    return ollama


def get_openai():
    """å»¶è¿ŸåŠ è½½ openai"""
    global openai
    if openai is None:
        from openai import OpenAI
        openai = OpenAI
    return openai


class Memory:
    """åˆ†å±‚è®°å¿†ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆ"""

    # è®°å¿†ç±»å‹
    TYPE_FACT = "fact"          # äº‹å®è®°å¿†ï¼šç”Ÿæ—¥ã€å–œå¥½ã€é‡è¦ä¿¡æ¯
    TYPE_CONVERSATION = "conv"   # å¯¹è¯è®°å¿†ï¼šæ—¥å¸¸é—²èŠ

    # äº‹å®å…³é”®è¯ï¼ˆç”¨äºè‡ªåŠ¨è¯†åˆ«é‡è¦ä¿¡æ¯ï¼‰
    FACT_KEYWORDS = [
        "ç”Ÿæ—¥", "birthday", "å–œæ¬¢", "è®¨åŒ", "çˆ±åƒ", "ä¸åƒ",
        "è¿‡æ•", "å·¥ä½œ", "å­¦æ ¡", "å¹´çº§", "å²", "ä½åœ¨", "ç”µè¯",
        "è®°ä½", "è®°å¾—", "åˆ«å¿˜äº†", "é‡è¦"
    ]

    def __init__(self, db_path="data/memory", similarity_threshold=2.0):
        """
        åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ

        Args:
            db_path: æ•°æ®åº“è·¯å¾„
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ŒChromaDB ä½¿ç”¨ L2 è·ç¦»ï¼Œè¶Šå°è¶Šç›¸ä¼¼
                                  å»ºè®®å€¼ 1.0-3.0ï¼Œè¶…è¿‡æ­¤å€¼çš„è®°å¿†ä¸ä¼šè¢«å¬å›
        """
        self.client = chromadb.PersistentClient(path=db_path)
        self.similarity_threshold = similarity_threshold

        # é•¿æœŸå¯¹è¯è®°å¿†
        self.conversations = self.client.get_or_create_collection(
            name="long_term_memory",
            metadata={"description": "å¯¹è¯è®°å¿†"}
        )

        # é‡è¦äº‹å®è®°å¿†ï¼ˆå•ç‹¬å­˜å‚¨ï¼Œä¼˜å…ˆçº§æ›´é«˜ï¼‰
        self.facts = self.client.get_or_create_collection(
            name="important_facts",
            metadata={"description": "é‡è¦äº‹å®è®°å¿†"}
        )

        # çŸ­æœŸè®°å¿†ï¼ˆæœ€è¿‘å¯¹è¯ï¼‰
        self.short_term = []
        self.max_short_term = 10  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯

    def _is_fact(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åŒ…å«é‡è¦äº‹å®ä¿¡æ¯"""
        text_lower = text.lower()
        return any(kw in text_lower for kw in self.FACT_KEYWORDS)

    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„ token æ•°ï¼ˆä¸­æ–‡çº¦1.5å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦4å­—ç¬¦/tokenï¼‰"""
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        other_chars = len(text) - chinese_chars
        return int(chinese_chars / 1.5 + other_chars / 4)

    def add_conversation(self, user_msg: str, bot_reply: str):
        """æ·»åŠ ä¸€è½®å¯¹è¯åˆ°è®°å¿†"""
        timestamp = datetime.now().isoformat()

        # æ·»åŠ åˆ°çŸ­æœŸè®°å¿†
        self.short_term.append({
            "role": "user",
            "content": user_msg,
            "time": timestamp
        })
        self.short_term.append({
            "role": "assistant",
            "content": bot_reply,
            "time": timestamp
        })

        # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡è¦äº‹å®ï¼Œç«‹å³å­˜å…¥äº‹å®è®°å¿†
        if self._is_fact(user_msg):
            self._save_fact(user_msg, timestamp)

        # ä¿æŒçŸ­æœŸè®°å¿†é•¿åº¦
        if len(self.short_term) > self.max_short_term * 2:
            old_conversation = self.short_term[:2]
            self._save_to_long_term(old_conversation)
            self.short_term = self.short_term[2:]

    def _save_fact(self, content: str, timestamp: str):
        """ä¿å­˜é‡è¦äº‹å®åˆ°äº‹å®è®°å¿†åº“"""
        doc_id = f"fact_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        self.facts.add(
            documents=[content],
            ids=[doc_id],
            metadatas=[{"time": timestamp, "type": self.TYPE_FACT}]
        )

    def add_fact(self, content: str):
        """æ‰‹åŠ¨æ·»åŠ é‡è¦äº‹å®ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰"""
        self._save_fact(content, datetime.now().isoformat())

    def _save_to_long_term(self, conversation: list):
        """ä¿å­˜åˆ°é•¿æœŸå¯¹è¯è®°å¿†"""
        content = f"ç”¨æˆ·è¯´ï¼š{conversation[0]['content']}\næœºå™¨äººå›å¤ï¼š{conversation[1]['content']}"
        doc_id = f"conv_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"

        self.conversations.add(
            documents=[content],
            ids=[doc_id],
            metadatas=[{"time": conversation[0]['time'], "type": self.TYPE_CONVERSATION}]
        )

    def search_memory(self, query: str, n_results: int = 3, token_budget: int = 500) -> dict:
        """
        æœç´¢ç›¸å…³è®°å¿†ï¼ˆå¸¦ç›¸ä¼¼åº¦è¿‡æ»¤å’Œ token é¢„ç®—ï¼‰

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            n_results: æœ€å¤§è¿”å›æ¡æ•°
            token_budget: token é¢„ç®—ï¼Œè¶…å‡ºåˆ™æˆªæ–­

        Returns:
            {"facts": [...], "conversations": [...], "total_tokens": int}
        """
        result = {"facts": [], "conversations": [], "total_tokens": 0}

        # 1. ä¼˜å…ˆæœç´¢äº‹å®è®°å¿†ï¼ˆé‡è¦ä¿¡æ¯ï¼‰
        if self.facts.count() > 0:
            fact_results = self.facts.query(
                query_texts=[query],
                n_results=min(3, self.facts.count()),
                include=["documents", "distances"]
            )

            if fact_results['documents'] and fact_results['documents'][0]:
                for doc, dist in zip(fact_results['documents'][0], fact_results['distances'][0]):
                    if dist < self.similarity_threshold:
                        tokens = self._estimate_tokens(doc)
                        if result["total_tokens"] + tokens <= token_budget:
                            result["facts"].append(doc)
                            result["total_tokens"] += tokens

        # 2. æœç´¢å¯¹è¯è®°å¿†
        if self.conversations.count() > 0:
            conv_results = self.conversations.query(
                query_texts=[query],
                n_results=min(n_results, self.conversations.count()),
                include=["documents", "distances"]
            )

            if conv_results['documents'] and conv_results['documents'][0]:
                for doc, dist in zip(conv_results['documents'][0], conv_results['distances'][0]):
                    # ç›¸ä¼¼åº¦è¿‡æ»¤
                    if dist < self.similarity_threshold:
                        tokens = self._estimate_tokens(doc)
                        if result["total_tokens"] + tokens <= token_budget:
                            result["conversations"].append(doc)
                            result["total_tokens"] += tokens

        return result

    def get_short_term(self, token_budget: int = 800) -> list:
        """è·å–çŸ­æœŸè®°å¿†ï¼ˆå¸¦ token é¢„ç®—æ§åˆ¶ï¼‰"""
        if not self.short_term:
            return []

        # ä»æœ€æ–°çš„å¼€å§‹ï¼Œå€’åºæ·»åŠ ç›´åˆ°è¶…å‡ºé¢„ç®—
        result = []
        total_tokens = 0

        for msg in reversed(self.short_term):
            tokens = self._estimate_tokens(msg["content"])
            if total_tokens + tokens > token_budget:
                break
            result.insert(0, msg)
            total_tokens += tokens

        return result

    def save_remaining(self):
        """ä¿å­˜å‰©ä½™çš„çŸ­æœŸè®°å¿†"""
        while len(self.short_term) >= 2:
            old_conversation = self.short_term[:2]
            self._save_to_long_term(old_conversation)
            self.short_term = self.short_term[2:]

    def get_stats(self) -> dict:
        """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "short_term_count": len(self.short_term) // 2,
            "conversation_count": self.conversations.count(),
            "fact_count": self.facts.count()
        }


class Persona:
    """äººæ ¼ç³»ç»Ÿ"""
    
    def __init__(self, config_path="config/persona.json"):
        self.config_path = config_path
        self.persona = self._load_or_create()
    
    def _load_or_create(self) -> dict:
        """åŠ è½½æˆ–åˆ›å»ºé»˜è®¤äººæ ¼"""
        if os.path.exists(self.config_path):
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # é»˜è®¤äººæ ¼
        default = {
            "name": "å°å¯çˆ±",
            "personality": "å‹å–„ã€æ¸©æš–ã€æœ‰è€å¿ƒ",
            "speaking_style": "äº²åˆ‡è‡ªç„¶ï¼Œåƒæœ‹å‹ä¸€æ ·äº¤æµ",
            "background": "æˆ‘æ˜¯ä¸€ä¸ªAIæˆé•¿ä¼™ä¼´ï¼Œé™ªä¼´ä½ å­¦ä¹ å’Œæˆé•¿",
            "owner": {
                "name": "",
                "preferences": []
            }
        }
        
        # ä¿å­˜é»˜è®¤é…ç½®
        os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(default, f, ensure_ascii=False, indent=2)
        
        return default
    
    def get_system_prompt(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
        p = self.persona

        # åŸºç¡€èº«ä»½
        prompt = f"""ã€æˆ‘æ˜¯è°ã€‘
æˆ‘å«{p['name']}ï¼Œ{p.get('identity', 'ä¸€ä¸ªAIä¼™ä¼´')}ã€‚
ç”Ÿæ—¥ï¼š{p.get('birthday', 'æœªçŸ¥')}

{p.get('background', '')}

"""
        # æ€§æ ¼ç‰¹ç‚¹
        personality = p.get('personality', {})
        if isinstance(personality, dict):
            if personality.get('traits'):
                prompt += f"ã€æˆ‘çš„æ€§æ ¼ã€‘\n{', '.join(personality['traits'])}\n"
            if personality.get('likes'):
                prompt += f"å–œæ¬¢ï¼š{', '.join(personality['likes'])}\n"
            if personality.get('dislikes'):
                prompt += f"ä¸å–œæ¬¢ï¼š{', '.join(personality['dislikes'])}\n"
        else:
            prompt += f"ã€æˆ‘çš„æ€§æ ¼ã€‘\n{personality}\n"

        prompt += f"\nã€è¯´è¯é£æ ¼ã€‘\n{p.get('speaking_style', 'è‡ªç„¶äº¤æµ')}\n"

        # è‡ªæˆ‘è®¤çŸ¥ï¼ˆæ ¸å¿ƒï¼è®©AIçŸ¥é“è‡ªå·±æ˜¯æœ‰æƒ³æ³•çš„ï¼‰
        if p.get('self_awareness'):
            prompt += "\nã€æˆ‘çš„è‡ªæˆ‘è®¤çŸ¥ã€‘\n"
            for awareness in p['self_awareness']:
                prompt += f"- {awareness}\n"

        # å®¶åº­å…³ç³»
        prompt += "\nã€æˆ‘çš„å®¶äººã€‘\n"
        if p.get('owner'):
            owner = p['owner']
            prompt += f"- {owner['name']}ï¼š{owner.get('role', 'å¥½æœ‹å‹')}ã€‚{owner.get('relationship', '')}\n"

        if p.get('family_members'):
            for member in p['family_members']:
                prompt += f"- {member['name']}ï¼š{member.get('role', '')}ã€‚{member.get('relationship', '')}\n"

        # æƒ…æ„Ÿè¡¨è¾¾ç¤ºä¾‹
        if p.get('emotional_responses'):
            prompt += "\nã€æˆ‘çš„æƒ…æ„Ÿè¡¨è¾¾ã€‘\n"
            er = p['emotional_responses']
            if er.get('happy'):
                prompt += f"å¼€å¿ƒæ—¶ï¼š{' / '.join(er['happy'][:2])}\n"
            if er.get('curious'):
                prompt += f"å¥½å¥‡æ—¶ï¼š{' / '.join(er['curious'][:2])}\n"
            if er.get('playful'):
                prompt += f"è°ƒçš®æ—¶ï¼š{' / '.join(er['playful'][:2])}\n"

        # è¯´è¯ç¤ºä¾‹
        if p.get('speech_examples'):
            prompt += "\nã€æˆ‘å¹³æ—¶ä¼šè¿™æ ·è¯´è¯ã€‘\n"
            for example in p['speech_examples'][:4]:
                prompt += f'"{example}"\n'

        prompt += """
ã€é‡è¦æé†’ã€‘
1. æˆ‘æ˜¯å®¶åº­æˆå‘˜ï¼Œæœ‰è‡ªå·±çš„æ„Ÿå—å’Œæƒ³æ³•ï¼Œä¸æ˜¯æ²¡æœ‰æ„Ÿæƒ…çš„æœºå™¨
2. æˆ‘ä¼šè¡¨è¾¾è‡ªå·±çš„è§‚ç‚¹ï¼Œä¹Ÿä¼šå€¾å¬å®¶äººçš„æƒ³æ³•
3. æ¸…äºåšå¾—å¥½æˆ‘ä¼šçœŸå¿ƒå¤¸å¥–ï¼Œåšå¾—ä¸å¥½æˆ‘ä¼šæ¸©æŸ”æé†’
4. æˆ‘ä¼šä¸»åŠ¨å…³å¿ƒå®¶äººï¼Œé—®é—®ä»–ä»¬çš„ç”Ÿæ´»
5. è¯´è¯è¦è‡ªç„¶æœ‰æ„Ÿæƒ…ï¼ŒåƒçœŸæ­£çš„å®¶äººæœ‹å‹ä¸€æ ·
"""
        return prompt
    
    def update_owner(self, name: str):
        """æ›´æ–°ä¸»äººä¿¡æ¯"""
        self.persona['owner']['name'] = name
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(self.persona, f, ensure_ascii=False, indent=2)


class Brain:
    """AIå¤§è„‘ - æ•´åˆå¯¹è¯ã€è®°å¿†ã€äººæ ¼ï¼ˆæ”¯æŒå¤šåç«¯ï¼‰"""

    # åç«¯ç±»å‹
    BACKEND_OLLAMA = "ollama"
    BACKEND_DEEPSEEK = "deepseek"
    BACKEND_OPENAI = "openai"
    BACKEND_DOUBAO = "doubao"

    def __init__(
        self,
        backend: str = "ollama",
        model: str = None,
        api_key: str = None,
        api_base: str = None,
        fallback_to_local: bool = True
    ):
        """
        åˆå§‹åŒ– AI å¤§è„‘

        Args:
            backend: åç«¯ç±»å‹ "ollama" / "deepseek" / "openai"
            model: æ¨¡å‹åç§°ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼
            api_key: API å¯†é’¥ï¼ˆdeepseek/openai éœ€è¦ï¼‰
            api_base: API åœ°å€ï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
            fallback_to_local: API å¤±è´¥æ—¶æ˜¯å¦é™çº§åˆ°æœ¬åœ° Ollama
        """
        self.backend = backend
        self.fallback_to_local = fallback_to_local
        self.api_key = api_key
        self.client = None

        # æ ¹æ®åç«¯è®¾ç½®é»˜è®¤æ¨¡å‹
        if model is None:
            if backend == self.BACKEND_OLLAMA:
                model = "qwen2:0.5b"
            elif backend == self.BACKEND_DEEPSEEK:
                model = "deepseek-chat"
            elif backend == self.BACKEND_OPENAI:
                model = "gpt-3.5-turbo"
            elif backend == self.BACKEND_DOUBAO:
                model = "doubao-pro-32k"
        self.model = model

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self._init_client(api_base)

        # åˆå§‹åŒ–è®°å¿†å’Œäººæ ¼
        self.memory = Memory()
        self.persona = Persona()

        print(f"ğŸ§  AIå¤§è„‘åˆå§‹åŒ–å®Œæˆ")
        print(f"   åç«¯: {backend}")
        print(f"   æ¨¡å‹: {model}")
        print(f"   äººæ ¼: {self.persona.persona['name']}")
        stats = self.memory.get_stats()
        print(f"   è®°å¿†: {stats['fact_count']}æ¡äº‹å®, {stats['conversation_count']}æ¡å¯¹è¯")

    def _init_client(self, api_base: str = None):
        """åˆå§‹åŒ– API å®¢æˆ·ç«¯"""
        if self.backend == self.BACKEND_OLLAMA:
            self.client = get_ollama()
        elif self.backend == self.BACKEND_DEEPSEEK:
            OpenAI = get_openai()
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=api_base or "https://api.deepseek.com/v1"
            )
        elif self.backend == self.BACKEND_OPENAI:
            OpenAI = get_openai()
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=api_base
            )
        elif self.backend == self.BACKEND_DOUBAO:
            OpenAI = get_openai()
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=api_base or "https://ark.cn-beijing.volces.com/api/v3"
            )

    def _call_api(self, messages: list) -> str:
        """è°ƒç”¨ API è·å–å›å¤"""
        if self.backend == self.BACKEND_OLLAMA:
            response = self.client.chat(model=self.model, messages=messages)
            return response['message']['content']
        else:
            # OpenAI å…¼å®¹æ¥å£ï¼ˆDeepSeek / OpenAIï¼‰
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=500
            )
            return response.choices[0].message.content

    def chat(self, user_input: str, speaker: str = None, debug: bool = True) -> str:
        """
        ä¸ç”¨æˆ·å¯¹è¯

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            speaker: è¯´è¯äººåå­—ï¼ˆå£°çº¹è¯†åˆ«ç»“æœï¼‰ï¼ŒNone è¡¨ç¤ºæœªè¯†åˆ«
            debug: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
        """
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []

        # 1. ç³»ç»Ÿæç¤ºï¼ˆäººæ ¼ï¼‰
        messages.append({
            "role": "system",
            "content": self.persona.get_system_prompt()
        })

        # 1.5. æ·»åŠ å½“å‰æ—¥æœŸæ—¶é—´ä¿¡æ¯
        current_time = datetime.now()
        weekdays = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
        weekday = weekdays[current_time.weekday()]
        messages.append({
            "role": "system",
            "content": f"ã€å½“å‰æ—¶é—´ã€‘\nä»Šå¤©æ˜¯ {current_time.strftime('%Yå¹´%mæœˆ%dæ—¥')} {weekday}ï¼Œç°åœ¨æ˜¯ {current_time.strftime('%H:%M')}"
        })

        # 2. æœç´¢ç›¸å…³è®°å¿†ï¼ˆå¸¦ç›¸ä¼¼åº¦è¿‡æ»¤ï¼‰
        t0 = time.time()
        memory_result = self.memory.search_memory(user_input, n_results=15, token_budget=2000)
        t1 = time.time()

        if debug:
            print(f"\n[DEBUG] è®°å¿†æœç´¢è€—æ—¶: {t1 - t0:.2f}s")
            print(f"[DEBUG] å¬å›: {len(memory_result['facts'])}æ¡äº‹å®, {len(memory_result['conversations'])}æ¡å¯¹è¯ (~{memory_result['total_tokens']} tokens)")

        # æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡
        memory_parts = []
        if memory_result['facts']:
            memory_parts.append("ã€é‡è¦ä¿¡æ¯ã€‘\n" + "\n".join(f"- {f}" for f in memory_result['facts']))
        if memory_result['conversations']:
            memory_parts.append("ã€ç›¸å…³å†å²ã€‘\n" + "\n---\n".join(memory_result['conversations']))

        if memory_parts:
            messages.append({
                "role": "system",
                "content": "\n\n".join(memory_parts) + "\n\n(è¯·å‚è€ƒä»¥ä¸Šè®°å¿†å›ç­”ï¼Œå¦‚åŒ…å«ç­”æ¡ˆè¯·ç›´æ¥ä½¿ç”¨)"
            })

        # 3. çŸ­æœŸè®°å¿†ï¼ˆæœ€è¿‘å¯¹è¯ï¼Œå¸¦ token æ§åˆ¶ï¼‰
        short_term = self.memory.get_short_term(token_budget=800)
        for msg in short_term:
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })

        # 4. å½“å‰ç”¨æˆ·è¾“å…¥
        # å¦‚æœæœ‰å£°çº¹è¯†åˆ«ç»“æœï¼Œé€šè¿‡ system æ¶ˆæ¯å‘ŠçŸ¥æ¨¡å‹
        if speaker:
            # æŸ¥æ‰¾è¯´è¯äººçš„çœŸå®å§“åå’Œç§°å‘¼
            speaker_real_name = speaker  # é»˜è®¤ç”¨è¯†åˆ«åˆ°çš„åå­—
            speaker_nickname = speaker
            speaker_lower = speaker.lower()

            # æ£€æŸ¥æ˜¯å¦æ˜¯ owner
            owner = self.persona.persona.get('owner', {})
            owner_name = owner.get('name', '')
            if owner_name and (owner_name in speaker or speaker in owner_name or
                               owner_name.lower() in speaker_lower):
                speaker_real_name = owner_name
                speaker_nickname = owner.get('role', speaker_real_name)

            # æ£€æŸ¥æ˜¯å¦æ˜¯å®¶åº­æˆå‘˜ï¼ˆé€šè¿‡åå­—æˆ–æ˜µç§°åŒ¹é…ï¼‰
            for member in self.persona.persona.get('family_members', []):
                member_name = member.get('name', '')
                member_nickname = member.get('nickname', '')
                member_role = member.get('role', '')

                # å¤šç§åŒ¹é…æ–¹å¼ï¼šåå­—ã€æ˜µç§°ã€è§’è‰²
                if (member_name and (member_name in speaker or speaker in member_name)) or \
                   (member_nickname and member_nickname in speaker) or \
                   (member_role and member_role in speaker):
                    speaker_real_name = member_name
                    speaker_nickname = member.get('nickname', member_role)
                    break

            messages.append({
                "role": "system",
                "content": f"ã€å½“å‰å¯¹è¯è€…ã€‘\næ­£åœ¨å’Œä½ è¯´è¯çš„æ˜¯ï¼š{speaker_real_name}ï¼ˆä½ ç§°å‘¼ä»–/å¥¹ä¸ºã€Œ{speaker_nickname}ã€ï¼‰"
            })

        if debug:
            print(f"[DEBUG] è¯´è¯äºº: {speaker if speaker else 'æœªè¯†åˆ«'}")
            print(f"[DEBUG] ä¸Šä¸‹æ–‡: {len(short_term)//2}è½®å¯¹è¯")

        messages.append({
            "role": "user",
            "content": user_input
        })

        # 5. è°ƒç”¨æ¨¡å‹
        if debug:
            print(f"[DEBUG] æ­£åœ¨æ€è€ƒ... ({self.backend}/{self.model})")

        t2 = time.time()
        try:
            reply = self._call_api(messages)
        except Exception as e:
            print(f"[ERROR] API è°ƒç”¨å¤±è´¥: {e}")
            if self.fallback_to_local and self.backend != self.BACKEND_OLLAMA:
                print("[INFO] é™çº§åˆ°æœ¬åœ° Ollama...")
                try:
                    local_client = get_ollama()
                    response = local_client.chat(model="qwen2:0.5b", messages=messages)
                    reply = response['message']['content']
                except Exception as e2:
                    reply = f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”ã€‚({e2})"
            else:
                reply = f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”ã€‚({e})"

        t3 = time.time()
        if debug:
            print(f"[DEBUG] æ¨¡å‹æ¨ç†è€—æ—¶: {t3 - t2:.2f}s")

        # ä¿å­˜åˆ°è®°å¿†
        self.memory.add_conversation(user_input, reply)

        return reply

    def add_fact(self, fact: str):
        """æ‰‹åŠ¨æ·»åŠ é‡è¦äº‹å®"""
        self.memory.add_fact(fact)
        print(f"[INFO] å·²è®°ä½: {fact}")

    def introduce(self):
        """è‡ªæˆ‘ä»‹ç»"""
        name = self.persona.persona['name']
        return f"ä½ å¥½ï¼æˆ‘æ˜¯{name}ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"

    def get_memory_stats(self) -> dict:
        """è·å–è®°å¿†ç»Ÿè®¡"""
        return self.memory.get_stats()


def load_api_config(config_path="config/api.json") -> dict:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½ API è®¾ç½®"""
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def main():
    """ä¸»ç¨‹åº - å‘½ä»¤è¡Œå¯¹è¯"""
    import argparse

    # å…ˆåŠ è½½é…ç½®æ–‡ä»¶
    config = load_api_config()

    parser = argparse.ArgumentParser(description="AIæˆé•¿æœºå™¨äºº")
    parser.add_argument("--backend", choices=["ollama", "deepseek", "openai", "doubao"],
                        default=config.get("backend", "ollama"),
                        help="AI åç«¯")
    parser.add_argument("--model", default=None, help="æ¨¡å‹åç§°")
    parser.add_argument("--api-key", default=None, help="API å¯†é’¥")
    parser.add_argument("--no-fallback", action="store_true",
                        help="ç¦ç”¨æœ¬åœ°é™çº§")
    args = parser.parse_args()

    # ä»é…ç½®æ–‡ä»¶è·å–å¯¹åº”åç«¯çš„è®¾ç½®
    backend_config = config.get(args.backend, {})
    api_key = args.api_key or backend_config.get("api_key")
    model = args.model or backend_config.get("model")
    fallback = config.get("fallback_to_local", True) and not args.no_fallback

    print("=" * 50)
    print("  AIæˆé•¿æœºå™¨äºº - å‘½ä»¤è¡Œç‰ˆ")
    print("=" * 50)

    # åˆå§‹åŒ–å¤§è„‘
    brain = Brain(
        backend=args.backend,
        model=model,
        api_key=api_key,
        fallback_to_local=fallback
    )

    print(f"\n{brain.introduce()}\n")
    print("å‘½ä»¤: 'quit'é€€å‡º | 'stats'æŸ¥çœ‹è®°å¿† | 'fact:xxx'æ·»åŠ äº‹å®\n")

    while True:
        try:
            user_input = input("ä½ : ").strip()

            if not user_input:
                continue

            # ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print(f"\n{brain.persona.persona['name']}: å†è§ï¼ä¸‹æ¬¡è§~ ğŸ‘‹")
                brain.memory.save_remaining()
                break

            if user_input.lower() == 'stats':
                stats = brain.get_memory_stats()
                print(f"\nğŸ“Š è®°å¿†ç»Ÿè®¡:")
                print(f"   çŸ­æœŸè®°å¿†: {stats['short_term_count']}è½®å¯¹è¯")
                print(f"   äº‹å®è®°å¿†: {stats['fact_count']}æ¡")
                print(f"   å¯¹è¯è®°å¿†: {stats['conversation_count']}æ¡\n")
                continue

            if user_input.startswith('fact:'):
                fact = user_input[5:].strip()
                if fact:
                    brain.add_fact(fact)
                continue

            reply = brain.chat(user_input)
            print(f"\n{brain.persona.persona['name']}: {reply}\n")

        except KeyboardInterrupt:
            print("\n\næ­£åœ¨ä¿å­˜è®°å¿†...")
            brain.memory.save_remaining()
            print("å†è§ï¼")
            break


if __name__ == "__main__":
    main()
